{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use OpenCV to get frames from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# HLS playlist URL\n",
    "hls_url = \"https://streamer4.brownrice.com/camdensnowbowl1/camdensnowbowl1.stream/main_playlist.m3u8\"\n",
    "\n",
    "cap = cv2.VideoCapture(hls_url)\n",
    "\n",
    "frame_count = 0\n",
    "frame_skip = 100  # Skip every 5 frames\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the HLS stream.\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Frame not received, ending stream\")\n",
    "            break\n",
    "        frame_count += 1\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "        # Process your frame (e.g., people counting) here\n",
    "\n",
    "        # For debugging, display the frame\n",
    "        cv2.imshow(\"HLS Stream\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count People in Web Cam Using YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "0: 384x640 9 persons, 21.5ms\n",
      "Speed: 4.1ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 20.6ms\n",
      "Speed: 11.6ms preprocess, 20.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 25.2ms\n",
      "Speed: 5.7ms preprocess, 25.2ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 23.7ms\n",
      "Speed: 9.9ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 50.1ms\n",
      "Speed: 5.0ms preprocess, 50.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 57.4ms\n",
      "Speed: 15.4ms preprocess, 57.4ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 21.5ms\n",
      "Speed: 5.3ms preprocess, 21.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 19.0ms\n",
      "Speed: 6.1ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 38.9ms\n",
      "Speed: 5.7ms preprocess, 38.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 24.4ms\n",
      "Speed: 6.2ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 20.1ms\n",
      "Speed: 3.9ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 20.4ms\n",
      "Speed: 7.7ms preprocess, 20.4ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 21.0ms\n",
      "Speed: 9.2ms preprocess, 21.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 21.6ms\n",
      "Speed: 8.5ms preprocess, 21.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 27.5ms\n",
      "Speed: 4.9ms preprocess, 27.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 21.3ms\n",
      "Speed: 5.9ms preprocess, 21.3ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 83.5ms\n",
      "Speed: 6.9ms preprocess, 83.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 21.3ms\n",
      "Speed: 3.4ms preprocess, 21.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 20.0ms\n",
      "Speed: 3.6ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 20.5ms\n",
      "Speed: 3.8ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 19.7ms\n",
      "Speed: 3.2ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 58.1ms\n",
      "Speed: 16.0ms preprocess, 58.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 19.6ms\n",
      "Speed: 4.0ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 18.8ms\n",
      "Speed: 3.9ms preprocess, 18.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 18.9ms\n",
      "Speed: 4.5ms preprocess, 18.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 19.1ms\n",
      "Speed: 6.2ms preprocess, 19.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 44.5ms\n",
      "Speed: 5.3ms preprocess, 44.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 56.1ms\n",
      "Speed: 6.2ms preprocess, 56.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 41.6ms\n",
      "Speed: 12.8ms preprocess, 41.6ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 37.5ms\n",
      "Speed: 5.4ms preprocess, 37.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 22.3ms\n",
      "Speed: 8.8ms preprocess, 22.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 56.6ms\n",
      "Speed: 6.2ms preprocess, 56.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 55.1ms\n",
      "Speed: 5.5ms preprocess, 55.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 37.9ms\n",
      "Speed: 4.8ms preprocess, 37.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 39.0ms\n",
      "Speed: 6.4ms preprocess, 39.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 39.0ms\n",
      "Speed: 6.1ms preprocess, 39.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 44.0ms\n",
      "Speed: 13.0ms preprocess, 44.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 50.8ms\n",
      "Speed: 8.4ms preprocess, 50.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 38.9ms\n",
      "Speed: 12.3ms preprocess, 38.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 46.7ms\n",
      "Speed: 6.2ms preprocess, 46.7ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 45.9ms\n",
      "Speed: 4.9ms preprocess, 45.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 40.9ms\n",
      "Speed: 4.8ms preprocess, 40.9ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 40.7ms\n",
      "Speed: 4.7ms preprocess, 40.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 41.3ms\n",
      "Speed: 5.8ms preprocess, 41.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 48.3ms\n",
      "Speed: 6.1ms preprocess, 48.3ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 55.5ms\n",
      "Speed: 5.0ms preprocess, 55.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.2ms\n",
      "Speed: 6.9ms preprocess, 41.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 54.2ms\n",
      "Speed: 6.3ms preprocess, 54.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 54.1ms\n",
      "Speed: 6.5ms preprocess, 54.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 43.8ms\n",
      "Speed: 9.8ms preprocess, 43.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 41.8ms\n",
      "Speed: 5.1ms preprocess, 41.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 41.9ms\n",
      "Speed: 4.7ms preprocess, 41.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 50.4ms\n",
      "Speed: 4.7ms preprocess, 50.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 47.7ms\n",
      "Speed: 7.6ms preprocess, 47.7ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 44.2ms\n",
      "Speed: 6.8ms preprocess, 44.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 45.8ms\n",
      "Speed: 6.1ms preprocess, 45.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 40.1ms\n",
      "Speed: 13.3ms preprocess, 40.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 41.3ms\n",
      "Speed: 4.5ms preprocess, 41.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 52.7ms\n",
      "Speed: 4.5ms preprocess, 52.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 57.2ms\n",
      "Speed: 13.8ms preprocess, 57.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 53.0ms\n",
      "Speed: 5.1ms preprocess, 53.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 40.4ms\n",
      "Speed: 16.8ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 47.3ms\n",
      "Speed: 5.4ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 43.7ms\n",
      "Speed: 10.8ms preprocess, 43.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 42.6ms\n",
      "Speed: 5.0ms preprocess, 42.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 64.1ms\n",
      "Speed: 5.6ms preprocess, 64.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 51.5ms\n",
      "Speed: 4.4ms preprocess, 51.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 25.5ms\n",
      "Speed: 4.0ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 66.8ms\n",
      "Speed: 5.1ms preprocess, 66.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 45.4ms\n",
      "Speed: 5.5ms preprocess, 45.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 61.3ms\n",
      "Speed: 4.5ms preprocess, 61.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 65.6ms\n",
      "Speed: 5.1ms preprocess, 65.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 70.3ms\n",
      "Speed: 5.1ms preprocess, 70.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 21.5ms\n",
      "Speed: 3.7ms preprocess, 21.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 20.1ms\n",
      "Speed: 3.2ms preprocess, 20.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 20.7ms\n",
      "Speed: 3.2ms preprocess, 20.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 70.5ms\n",
      "Speed: 9.6ms preprocess, 70.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 26.0ms\n",
      "Speed: 6.9ms preprocess, 26.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 21.0ms\n",
      "Speed: 4.7ms preprocess, 21.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 22.0ms\n",
      "Speed: 3.3ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 75.8ms\n",
      "Speed: 5.0ms preprocess, 75.8ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Import the necessary classes - this is a new issue with pytorch 2.6, could use 2.4 and not have to import all of these layers and add them to the globals list\n",
    "from ultralytics.nn.tasks import DetectionModel  # Already imported for YOLOv8 models\n",
    "from torch.nn.modules.container import Sequential    # For Sequential layers\n",
    "from ultralytics.nn.modules.conv import Conv         # For Conv layers defined by Ultralytics\n",
    "from torch.nn.modules.conv import Conv2d              # For PyTorch's Conv2d layer\n",
    "from torch.nn.modules.batchnorm import BatchNorm2d\n",
    "from torch.nn.modules.activation import SiLU               # PyTorch's SiLU activation\n",
    "from ultralytics.nn.modules.block import C2f                       # Ultralytics' C2f block\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from ultralytics.nn.modules.block import Bottleneck\n",
    "from ultralytics.nn.modules.block import SPPF\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "from torch.nn.modules.upsampling import Upsample\n",
    "from ultralytics.nn.modules.conv import Concat\n",
    "from ultralytics.nn.modules.head import Detect\n",
    "from ultralytics.nn.modules.block import DFL\n",
    "torch.serialization.add_safe_globals([\n",
    "    DetectionModel, Sequential, Conv, Conv2d, BatchNorm2d, SiLU, C2f, ModuleList,\n",
    "    Bottleneck, SPPF, MaxPool2d, Upsample, Concat, Detect, DFL\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pretrained YOLOv8 model and move it to the appropriate device\n",
    "model = YOLO(\"yolov8n.pt\").to(device)\n",
    "\n",
    "# Define the HLS stream URL (the direct stream URL you extracted)\n",
    "hls_url = \"https://streamer4.brownrice.com/camdensnowbowl1/camdensnowbowl1.stream/main_playlist.m3u8\"\n",
    "\n",
    "# Open the video stream\n",
    "cap = cv2.VideoCapture(hls_url)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the video stream.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 20  # Process every 20th frame\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames until we hit the desired interval\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    # Run YOLOv8 inference on the current frame.\n",
    "    results = model(frame)\n",
    "    \n",
    "    # We'll use a copy of the frame to draw annotations.\n",
    "    annotated_frame = frame.copy()\n",
    "    people_count = 0\n",
    "\n",
    "    # Process each detection result\n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes.data.cpu().numpy()  # shape: (num_boxes, 6)\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2, conf, cls = box\n",
    "                # In COCO, the 'person' class typically has an id of 0.\n",
    "                if int(cls) >= 0:\n",
    "                    bbox_color = (0, 255, 0)  # Green\n",
    "                    if cls != 0:\n",
    "                        bbox_color = (255, 0, 0)\n",
    "                    cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), bbox_color, 2)\n",
    "                    people_count += 1\n",
    "                    # Draw the bounding box and label on the frame.\n",
    "                    cv2.putText(\n",
    "                        annotated_frame,\n",
    "                        f\"{int(cls)} {conf:.2f}\",\n",
    "                        (int(x1), int(y1) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (0, 255, 0),\n",
    "                        2,\n",
    "                    )\n",
    "    \n",
    "    # Overlay the people count on the frame.\n",
    "    cv2.putText(\n",
    "        annotated_frame,\n",
    "        f\"People Count: {people_count}\",\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "    )\n",
    "    \n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"YOLOv8 People Counting\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the stream and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset we can use to fine tune the model for counting people on this web cam\n",
    "Saves every 1000th frame into the dataset/images/train folder and the associated YOLOv8 detected people annotations into the dataset/labels/train folder\n",
    "\n",
    "Idea is we then go through these images after we gather a lot and improve upon the annotations. Then we fine tune the YOLO model with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Saved image: dataset/images/train/frame_1_1738874235.jpg\n",
      "\n",
      "0: 384x640 4 persons, 64.1ms\n",
      "Speed: 13.7ms preprocess, 64.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Saved annotations: dataset/labels/train/frame_1_1738874235.txt\n",
      "Saved image: dataset/images/train/frame_1001_1738874278.jpg\n",
      "\n",
      "0: 384x640 8 persons, 58.6ms\n",
      "Speed: 6.7ms preprocess, 58.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Saved annotations: dataset/labels/train/frame_1001_1738874278.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Set up safe globals for PyTorch 2.6+ (include only if necessary)\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from torch.nn.modules.container import Sequential, ModuleList\n",
    "from ultralytics.nn.modules.conv import Conv, Concat\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "from torch.nn.modules.batchnorm import BatchNorm2d\n",
    "from torch.nn.modules.activation import SiLU\n",
    "from ultralytics.nn.modules.block import C2f, Bottleneck, SPPF, DFL\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "from torch.nn.modules.upsampling import Upsample\n",
    "from ultralytics.nn.modules.head import Detect\n",
    "torch.serialization.add_safe_globals([\n",
    "    DetectionModel, Sequential, Conv, Conv2d, BatchNorm2d, SiLU, C2f, ModuleList,\n",
    "    Bottleneck, SPPF, MaxPool2d, Upsample, Concat, Detect, DFL\n",
    "])\n",
    "\n",
    "# Adjustable parameters\n",
    "WEBCAM_URL = \"https://streamer4.brownrice.com/camdensnowbowl1/camdensnowbowl1.stream/main_playlist.m3u8\"\n",
    "FRAME_INTERVAL = 1000  # Process every 1000th frame\n",
    "CONF_THRESHOLD = 0.4   # Confidence threshold\n",
    "IMG_DIR = 'dataset/images/train'\n",
    "LABEL_DIR = 'dataset/labels/train'\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\").to(device)\n",
    "\n",
    "cap = cv2.VideoCapture(WEBCAM_URL)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the video stream.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    # Process only every FRAME_INTERVAL frame\n",
    "    if frame_count % FRAME_INTERVAL != 1:\n",
    "        continue\n",
    "\n",
    "    # Save the raw frame\n",
    "    timestamp = int(time.time())\n",
    "    img_filename = os.path.join(IMG_DIR, f\"frame_{frame_count}_{timestamp}.jpg\")\n",
    "    cv2.imwrite(img_filename, frame)\n",
    "    print(f\"Saved image: {img_filename}\")\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Open a .txt file for writing the annotations in YOLO format\n",
    "    txt_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "    txt_filename = txt_filename.replace(\"images\", \"labels\")\n",
    "    with open(txt_filename, \"w\") as f:\n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                boxes = result.boxes.data.cpu().numpy()  # each row: [x1, y1, x2, y2, conf, cls]\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2, conf, cls = box\n",
    "                    if conf >= CONF_THRESHOLD and int(cls) == 0:  # Only person (class 0)\n",
    "                        # Convert bounding box to YOLO format (normalized)\n",
    "                        x_center = ((x1 + x2) / 2.0) / width\n",
    "                        y_center = ((y1 + y2) / 2.0) / height\n",
    "                        bbox_width = (x2 - x1) / width\n",
    "                        bbox_height = (y2 - y1) / height\n",
    "                        # Write annotation line: class x_center y_center width height\n",
    "                        f.write(f\"0 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "    print(f\"Saved annotations: {txt_filename}\")\n",
    "\n",
    "    # Optionally, display the frame (with no annotations drawn)\n",
    "    cv2.imshow(\"Dataset Collection\", frame)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "people_counter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
